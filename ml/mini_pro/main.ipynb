{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## module needed\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for splitting the song into equal size (1000)\n",
    "\n",
    "def cut_song(song):\n",
    "    start = 0\n",
    "    end = len(song)\n",
    "\n",
    "    song_pieces = []\n",
    "\n",
    "    while start + 100000 < end:\n",
    "        song_pieces.append(song[start:start+100000])\n",
    "\n",
    "    start += 100000\n",
    "\n",
    "    return song_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for converting into melspectrograms\n",
    "\n",
    "def prepare_song(song_path):\n",
    "    list_matrices = []\n",
    "    y,sr = librosa.load(song_path,sr=22050)\n",
    "    song_pieces = cut_song(y)\n",
    "    for song_piece in song_pieces:\n",
    "        melspect = librosa.feature.melspectrogram(song_piece)\n",
    "        list_matrices.append(melspect)\n",
    "    return list_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n"
     ]
    }
   ],
   "source": [
    "## getting all the genre\n",
    "\n",
    "genre = os.listdir('tracks')\n",
    "print(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 done\n",
      "2/10 done\n",
      "3/10 done\n",
      "4/10 done\n",
      "5/10 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunil/.local/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to add this file tracks/jazz/jazz.00054.wav\n",
      "6/10 done\n",
      "7/10 done\n",
      "8/10 done\n",
      "9/10 done\n",
      "10/10 done\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(genre)):\n",
    "    for song_name in os.listdir(os.path.join('tracks',genre[i])):\n",
    "        try:\n",
    "            song_pieces = prepare_song(os.path.join('tracks', genre[i], song_name))\n",
    "            X += song_pieces\n",
    "            y += ([i]*len(song_pieces))\n",
    "        except Exception:\n",
    "            print(f\"unable to add this file {os.path.join('tracks', genre[i], song_name)}\")\n",
    "        \n",
    "    print(f\"{i+1}/{len(genre)} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preserving the X and y\n",
    "\n",
    "with open('X.pickle', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "\n",
    "with open('y.pickle', 'wb') as f:\n",
    "    pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the data back\n",
    "\n",
    "X = pickle.load(open('X.pickle', 'rb'))\n",
    "X = np.array(X).reshape(-1, 128, 196, 1)\n",
    "y = pickle.load(open('y.pickle', 'rb'))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train / testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## packages\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, \n",
    "                                                y_test,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 194, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 97, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 95, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 47, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 45, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 80640)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                5161024   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,217,418\n",
      "Trainable params: 5,217,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## model design\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 196, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "# since ther are 10 labels\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 [==============================] - 112s 882ms/step - loss: -41.4381 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 107s 847ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 110s 874ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 108s 861ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 106s 844ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 100s 796ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 21104s 169s/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 105s 834ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 104s 823ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 103s 820ms/step - loss: -41.9157 - accuracy: 0.1220 - val_loss: -37.7128 - val_accuracy: 0.1345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics='accuracy')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, \n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 128, 196, 1), found shape=(32, 196, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20388/3071856150.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\sunil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 128, 196, 1), found shape=(32, 196, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.predict(X[5])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "565ac28c2ecb613dc0d7bb0cf1695225e2699c1e004732cce50cb5eaa7cc92ba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
